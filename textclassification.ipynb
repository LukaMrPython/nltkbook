{
 "metadata": {
  "name": "",
  "signature": "sha256:b1752f6c94e5e718393552af0e9cf76bd1c5ccc10b771aeef06ad4342d5ebffe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn import metrics\n",
      "from operator import itemgetter\n",
      "from sklearn.metrics import classification_report\n",
      "import csv\n",
      "import os\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "\n",
      "\n",
      "nyt = open('C:/Users/a549369/Documents/book/SMSSpamCollection') # check the structure of this file!\n",
      "nyt_data = []\n",
      "nyt_labels = []\n",
      "csv_reader = csv.reader(nyt,delimiter='\\t')\n",
      "\n",
      "for line in csv_reader:\n",
      "    #print line \n",
      "    nyt_labels.append(line[0])\n",
      "    nyt_data.append(line[1])\n",
      "\n",
      "nyt.close()\n",
      "\n",
      "trainset_size = int(round(len(nyt_data)*0.75)) # i chose this threshold arbitrarily...to discuss\n",
      "print 'The training set size for this classifier is ' + str(trainset_size) + '\\n'\n",
      "\n",
      "x_train = np.array([''.join(el) for el in nyt_data[0:trainset_size]])\n",
      "y_train = np.array([el for el in nyt_labels[0:trainset_size]])\n",
      "\n",
      "x_test = np.array([''.join(el) for el in nyt_data[trainset_size+1:len(nyt_data)]]) \n",
      "y_test = np.array([el for el in nyt_labels[trainset_size+1:len(nyt_labels)]]) \n",
      "\n",
      "\n",
      "print x_train\n",
      "print y_train\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The training set size for this classifier is 4179\n",
        "\n",
        "[ 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
        " 'Ok lar... Joking wif u oni...'\n",
        " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
        " ...,\n",
        " \"How are you doing. How's the queen. Are you going for the royal wedding\"\n",
        " \"He's in lag. That's just the sad part but we keep in touch thanks to skype\"\n",
        " 'Ok lor then we go tog lor...']\n",
        "['ham' 'ham' 'spam' ..., 'ham' 'ham' 'ham']\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(min_df=2,\n",
      " ngram_range=(1, 2), \n",
      " stop_words='english', \n",
      " strip_accents='unicode', \n",
      " norm='l2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "def featurize(tweet):\n",
      "    # tokenize into words\n",
      "    tokens = [word for sent in sent_tokenize(tweet) for word in word_tokenize(sent)]\n",
      "\n",
      "    # remove stopwords\n",
      "    stop = stopwords.words('english')\n",
      "    tokens = [token for token in tokens if token not in stop]\n",
      "\n",
      "    # remove words less than three letters\n",
      "    tokens = [word for word in tokens if len(word) >= 3]\n",
      "\n",
      "    # lower capitalization\n",
      "    tokens = [word.lower() for word in tokens]\n",
      "\n",
      "    # lemmatize\n",
      "    lmtzr = WordNetLemmatizer()\n",
      "    tokens = [lmtzr.lemmatize(word) for word in tokens]\n",
      "\n",
      "    return tokens\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = vectorizer.fit_transform(x_train)\n",
      "X_test = vectorizer.transform(x_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "clf = MultinomialNB().fit(X_train, y_train)\n",
      "\n",
      "y_nb_predicted = clf.predict(X_test)\n",
      "print y_nb_predicted\n",
      "\n",
      "\n",
      "print '\\nHere is the classification report:'\n",
      "print classification_report(y_test, y_nb_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['ham' 'ham' 'ham' ..., 'ham' 'ham' 'ham']\n",
        "\n",
        "Here is the classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        ham       0.97      1.00      0.98      1210\n",
        "       spam       1.00      0.77      0.87       182\n",
        "\n",
        "avg / total       0.97      0.97      0.97      1392\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "feature_names = vectorizer.get_feature_names()\n",
      "coefs = clf.coef_\n",
      "intercept = clf.intercept_\n",
      "coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
      "n=50\n",
      "top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
      "for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
      "    print('\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s' % (coef_1, fn_1, coef_2, fn_2))\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t-9.1602\t10 den         \t\t-6.0396\tfree           \n",
        "\t-9.1602\t15             \t\t-6.3487\ttxt            \n",
        "\t-9.1602\t1hr            \t\t-6.5067\ttext           \n",
        "\t-9.1602\t1st ur         \t\t-6.5393\tclaim          \n",
        "\t-9.1602\t2go            \t\t-6.5681\treply          \n",
        "\t-9.1602\t2marrow        \t\t-6.5808\tmobile         \n",
        "\t-9.1602\t2morrow        \t\t-6.5858\tstop           \n",
        "\t-9.1602\t2mrw           \t\t-6.6124\tur             \n",
        "\t-9.1602\t2nd innings    \t\t-6.6245\tprize          \n",
        "\t-9.1602\t2nd ur         \t\t-6.7856\twww            \n",
        "\t-9.1602\t30             \t\t-6.8133\tuk             \n",
        "\t-9.1602\t30 want        \t\t-6.8569\twon            \n",
        "\t-9.1602\t30ish          \t\t-6.8625\tnew            \n",
        "\t-9.1602\t3d             \t\t-6.8899\tservice        \n",
        "\t-9.1602\t3d imp         \t\t-6.9237\t150p           \n",
        "\t-9.1602\t3rd            \t\t-6.9438\tcash           \n",
        "\t-9.1602\t3rd ur         \t\t-6.9575\turgent         \n",
        "\t-9.1602\t48             \t\t-7.0111\tnokia          \n",
        "\t-9.1602\t4a             \t\t-7.0369\tjust           \n",
        "\t-9.1602\t4d             \t\t-7.0401\twin            \n",
        "\t-9.1602\t4get           \t\t-7.0761\tmsg            \n",
        "\t-9.1602\t4th            \t\t-7.0855\tweek           \n",
        "\t-9.1602\t4th ur         \t\t-7.1018\tcontact        \n",
        "\t-9.1602\t530            \t\t-7.1060\t50             \n",
        "\t-9.1602\t530 lor        \t\t-7.1069\tcom            \n",
        "\t-9.1602\t5min           \t\t-7.1100\t18             \n",
        "\t-9.1602\t5pm            \t\t-7.1253\tcustomer       \n",
        "\t-9.1602\t5th            \t\t-7.1299\ttone           \n",
        "\t-9.1602\t5th ur         \t\t-7.1596\tsend           \n",
        "\t-9.1602\t65             \t\t-7.1625\tguaranteed     \n",
        "\t-9.1602\t6hrs           \t\t-7.2030\t16             \n",
        "\t-9.1602\t6pm            \t\t-7.2060\tchat           \n",
        "\t-9.1602\t6th            \t\t-7.2428\t1000           \n",
        "\t-9.1602\t6th ur         \t\t-7.2527\tringtone       \n",
        "\t-9.1602\t700            \t\t-7.2605\tcs             \n",
        "\t-9.1602\t7ish           \t\t-7.2606\t500            \n",
        "\t-9.1602\t7th            \t\t-7.2821\tphone          \n",
        "\t-9.1602\t7th 6th        \t\t-7.2986\tmessage        \n",
        "\t-9.1602\t8am            \t\t-7.3370\tvideo          \n",
        "\t-9.1602\t8th            \t\t-7.3690\tsms            \n",
        "\t-9.1602\t930            \t\t-7.3829\tawarded        \n",
        "\t-9.1602\t9ja            \t\t-7.3940\tmin            \n",
        "\t-9.1602\t9t             \t\t-7.4027\t100            \n",
        "\t-9.1602\t____           \t\t-7.4068\twk             \n",
        "\t-9.1602\t____ joy       \t\t-7.4177\tdraw           \n",
        "\t-9.1602\taathi          \t\t-7.4215\tlandline       \n",
        "\t-9.1602\taathi dear     \t\t-7.4218\tline           \n",
        "\t-9.1602\taathi love     \t\t-7.4406\t000            \n",
        "\t-9.1602\tabi            \t\t-7.4465\ttones          \n",
        "\t-9.1602\tability        \t\t-7.4808\t150ppm         \n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "clf=SGDClassifier(alpha=.0001, n_iter=50).fit(X_train, y_train)\n",
      "\n",
      "y_pred = clf.predict(X_test)\n",
      "\n",
      "print '\\nHere is the classification report:'\n",
      "print classification_report(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Here is the classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        ham       0.98      1.00      0.99      1210\n",
        "       spam       0.98      0.90      0.93       182\n",
        "\n",
        "avg / total       0.98      0.98      0.98      1392\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = vectorizer.get_feature_names()\n",
      "coefs = clf.coef_\n",
      "intercept = clf.intercept_\n",
      "coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
      "n=50\n",
      "top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
      "for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
      "    print('\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s' % (coef_1, fn_1, coef_2, fn_2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t-1.5903\troad           \t\t2.8156\tuk             \n",
        "\t-1.4087\tok             \t\t2.6908\ttxt            \n",
        "\t-1.2589\tmail           \t\t2.4647\tclaim          \n",
        "\t-1.2317\thome           \t\t2.1173\tservice        \n",
        "\t-1.0969\tjourney        \t\t2.0186\t150p           \n",
        "\t-1.0707\tmorning        \t\t2.0005\tringtoneking   \n",
        "\t-1.0437\tyup            \t\t1.9779\twww            \n",
        "\t-0.9812\tgd             \t\t1.9698\t50             \n",
        "\t-0.9643\tfullonsms      \t\t1.9633\tringtone       \n",
        "\t-0.9643\tfullonsms com  \t\t1.9281\tservices       \n",
        "\t-0.9268\tlater          \t\t1.9086\tbrought        \n",
        "\t-0.9191\tlol            \t\t1.8523\tsale           \n",
        "\t-0.8778\tsaid           \t\t1.8296\t500            \n",
        "\t-0.8722\talright        \t\t1.7763\tfilthy         \n",
        "\t-0.8696\tgonna          \t\t1.7457\trgds           \n",
        "\t-0.8423\tll text        \t\t1.7436\t0800           \n",
        "\t-0.7940\thappy          \t\t1.6970\tmobile         \n",
        "\t-0.7851\tknowing        \t\t1.6834\tbid            \n",
        "\t-0.7849\tbillion        \t\t1.6452\tvideo          \n",
        "\t-0.7479\tdid            \t\t1.6342\tprize          \n",
        "\t-0.7416\tdeciding       \t\t1.6129\t18             \n",
        "\t-0.7268\tscrounge       \t\t1.6058\tnew message    \n",
        "\t-0.7195\tda             \t\t1.5743\t88066          \n",
        "\t-0.7171\tyijue          \t\t1.5447\tcom            \n",
        "\t-0.7038\tglad           \t\t1.5390\torder          \n",
        "\t-0.6976\tsorry          \t\t1.5183\twap            \n",
        "\t-0.6956\tcheers         \t\t1.4645\tfreemsg        \n",
        "\t-0.6873\tawesome        \t\t1.4407\ttones          \n",
        "\t-0.6748\they            \t\t1.4388\tsms            \n",
        "\t-0.6725\tfb             \t\t1.4266\tlandline       \n",
        "\t-0.6594\tgoogle         \t\t1.4085\thttp           \n",
        "\t-0.6564\ttype           \t\t1.3709\tinformation    \n",
        "\t-0.6447\tkate           \t\t1.3697\tstd            \n",
        "\t-0.6392\tcustomer place \t\t1.3536\tcollection     \n",
        "\t-0.6215\tprincess       \t\t1.3423\trate           \n",
        "\t-0.6206\tway            \t\t1.3421\twin            \n",
        "\t-0.6072\tyes            \t\t1.3405\tsend stop      \n",
        "\t-0.6023\tthink          \t\t1.3315\tsept           \n",
        "\t-0.6011\tthank          \t\t1.3256\tnokia          \n",
        "\t-0.5891\tshare          \t\t1.3050\t88066 lost     \n",
        "\t-0.5844\tdoing          \t\t1.2977\tparis          \n",
        "\t-0.5648\taddress        \t\t1.2860\twon            \n",
        "\t-0.5604\tcome           \t\t1.2851\tstop           \n",
        "\t-0.5549\tatm            \t\t1.2819\t10p            \n",
        "\t-0.5549\tthreats        \t\t1.2805\tgood luck      \n",
        "\t-0.5547\tdoesnt         \t\t1.2664\t1000           \n",
        "\t-0.5485\tll             \t\t1.2657\tnetworks       \n",
        "\t-0.5464\tasks           \t\t1.2577\tsunshine       \n",
        "\t-0.5443\tcause          \t\t1.2369\t10am           \n",
        "\t-0.5438\tgot            \t\t1.2295\t16             \n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "svm_classifier = LinearSVC().fit(X_train, y_train)\n",
      "\n",
      "y_svm_predicted = svm_classifier.predict(X_test)\n",
      "\n",
      "print '\\nHere is the classification report:'\n",
      "print classification_report(y_test, y_svm_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Here is the classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        ham       0.99      1.00      0.99      1210\n",
        "       spam       0.98      0.91      0.94       182\n",
        "\n",
        "avg / total       0.98      0.98      0.98      1392\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = vectorizer.get_feature_names()\n",
      "coefs = svm_classifier.coef_\n",
      "intercept = svm_classifier.intercept_\n",
      "coefs_with_fns = sorted(zip(svm_classifier.coef_[0], feature_names))\n",
      "n=50\n",
      "top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
      "for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
      "    print('\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s' % (coef_1, fn_1, coef_2, fn_2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t-0.9253\troad           \t\t2.2754\ttxt            \n",
        "\t-0.8619\tok             \t\t2.2043\tuk             \n",
        "\t-0.7368\tmail           \t\t2.0032\tclaim          \n",
        "\t-0.7185\thome           \t\t1.7047\t150p           \n",
        "\t-0.6559\tlol            \t\t1.6762\tservice        \n",
        "\t-0.6366\talright        \t\t1.6049\twww            \n",
        "\t-0.6165\tlater          \t\t1.5625\tmobile         \n",
        "\t-0.6074\tmorning        \t\t1.5059\t50             \n",
        "\t-0.5956\tsaid           \t\t1.4810\tringtone       \n",
        "\t-0.5727\tyup            \t\t1.4065\tprize          \n",
        "\t-0.5658\thappy          \t\t1.4028\tvideo          \n",
        "\t-0.5628\tda             \t\t1.3973\tservices       \n",
        "\t-0.5604\they            \t\t1.3483\t500            \n",
        "\t-0.5568\tgonna          \t\t1.3439\t18             \n",
        "\t-0.5550\tjourney        \t\t1.2660\tsale           \n",
        "\t-0.5022\tway            \t\t1.2289\tringtoneking   \n",
        "\t-0.5003\tgd             \t\t1.2073\t0800           \n",
        "\t-0.4977\tfullonsms      \t\t1.1981\twin            \n",
        "\t-0.4977\tfullonsms com  \t\t1.1765\thttp           \n",
        "\t-0.4956\tcustomer place \t\t1.1501\t88066          \n",
        "\t-0.4811\tdid            \t\t1.1460\tfilthy         \n",
        "\t-0.4722\tknowing        \t\t1.1222\ttones          \n",
        "\t-0.4690\tll text        \t\t1.1212\tcom            \n",
        "\t-0.4687\tyes            \t\t1.1207\treply          \n",
        "\t-0.4660\tgot            \t\t1.1206\tsms            \n",
        "\t-0.4547\tlt             \t\t1.1166\tnokia          \n",
        "\t-0.4525\tll             \t\t1.1111\tbrought        \n",
        "\t-0.4388\tawesome        \t\t1.1027\tnew            \n",
        "\t-0.4382\tdeleted        \t\t1.0882\tchat           \n",
        "\t-0.4372\tkate           \t\t1.0784\twon            \n",
        "\t-0.4352\tgt             \t\t1.0679\twap            \n",
        "\t-0.4352\tyijue          \t\t1.0561\tstop           \n",
        "\t-0.4305\tprincess       \t\t1.0485\t100            \n",
        "\t-0.4257\tlt gt          \t\t1.0477\tnew message    \n",
        "\t-0.4211\tthink          \t\t1.0335\tlandline       \n",
        "\t-0.4175\tid             \t\t1.0320\trate           \n",
        "\t-0.4127\tperson         \t\t1.0298\ttone           \n",
        "\t-0.4114\tdon            \t\t1.0274\t1000           \n",
        "\t-0.4110\tsorry          \t\t1.0258\tfreemsg        \n",
        "\t-0.4056\tbak            \t\t1.0225\torder          \n",
        "\t-0.4023\tfb             \t\t1.0203\tbid            \n",
        "\t-0.3995\tscrounge       \t\t0.9933\tstd            \n",
        "\t-0.3934\tmachan         \t\t0.9913\t10p            \n",
        "\t-0.3909\tcheers         \t\t0.9719\t16             \n",
        "\t-0.3881\tdoing          \t\t0.9605\tcs             \n",
        "\t-0.3878\tcome           \t\t0.9590\trgds           \n",
        "\t-0.3859\tdoesnt         \t\t0.9549\tsexy           \n",
        "\t-0.3842\tpls            \t\t0.9416\tsorry missed   \n",
        "\t-0.3802\ttxt bak        \t\t0.9348\tgames          \n",
        "\t-0.3764\ttype           \t\t0.9001\tcollection     \n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}